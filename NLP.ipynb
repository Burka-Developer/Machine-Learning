{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/XAYjqz7UYVKyjOdq3Urb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Burka-Developer/Machine-Learning/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization\n",
        "\n",
        "Text ko tukdon mein todna ‚Äî words, characters, or sentences.\n"
      ],
      "metadata": {
        "id": "bOTt_KGu2pk-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYxTu5xe0jYT"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"I love Natural Language Processing!\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalization\n",
        "\n",
        "Clean text ‚Äî lowercase, remove punctuations, extra spaces.\n"
      ],
      "metadata": {
        "id": "aSNuizWK26Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"Hello, NLP World!!   \"\n",
        "normalized = re.sub(r'[^\\w\\s]', '', text.lower()).strip()\n",
        "print(normalized)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU_oRgwG3Ac2",
        "outputId": "2b6f17dc-cfc7-4120-c113-daca2553dd20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello nlp world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming\n",
        "\n",
        "Word ka root nikalna (rough cut). Like: running ‚Üí run"
      ],
      "metadata": {
        "id": "kJ5U1bdf3OTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "words = [\"running\", \"runner\", \"ran\", \"easily\", \"fairly\"]\n",
        "stems = [stemmer.stem(w) for w in words]\n",
        "print(stems)\n"
      ],
      "metadata": {
        "id": "D0ximSbn3Tcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization\n",
        "\n",
        "Smarter stemming ‚Äî uses grammar rules and context."
      ],
      "metadata": {
        "id": "Z4sodf2i3Xju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = [\"running\", \"better\", \"flies\"]\n",
        "lemmas = [lemmatizer.lemmatize(w, pos='v') for w in words]\n",
        "print(lemmas)\n"
      ],
      "metadata": {
        "id": "yc7WWPRJ3c_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus\n",
        "\n",
        "Collection of text ‚Äî jaise ek library."
      ],
      "metadata": {
        "id": "WCZ9CRn93jFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "print(gutenberg.fileids())  # list of corpora\n",
        "print(gutenberg.raw('austen-emma.txt')[:300])\n"
      ],
      "metadata": {
        "id": "WYhZ-QD13nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop Words\n",
        "\n",
        "Words like \"the\", \"is\", \"in\" ‚Äî jo zyada meaning nahi dete."
      ],
      "metadata": {
        "id": "zXqXqtP83pXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "words = word_tokenize(\"This is a very important message.\")\n",
        "filtered = [w for w in words if w.lower() not in stopwords.words('english')]\n",
        "print(filtered)\n"
      ],
      "metadata": {
        "id": "cNeViQDn3thY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POS Tagging (Part of Speech)\n",
        "\n",
        "Har word ka role: noun, verb, adjective..."
      ],
      "metadata": {
        "id": "-HYXwL0f4CgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "sentence = word_tokenize(\"Dogs bark loudly.\")\n",
        "tags = nltk.pos_tag(sentence)\n",
        "print(tags)\n"
      ],
      "metadata": {
        "id": "nYdWdOSC4HHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parsing\n",
        "\n",
        "Grammar + structure analysis (sentence ka skeleton)"
      ],
      "metadata": {
        "id": "xALFI8-X4Jh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import benepar\n",
        "import spacy\n",
        "spacy.prefer_gpu()\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"The cat sat on the mat.\")\n",
        "for token in doc:\n",
        "    print(f\"{token.text} --> {token.dep_}\")\n"
      ],
      "metadata": {
        "id": "ooL5IG7R4N5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Syntax\n",
        "\n",
        "Rules of sentence ‚Äî jaise subject, verb, object order.\n",
        "\n",
        "üß† No special code needed ‚Äî part of parsing & POS"
      ],
      "metadata": {
        "id": "-K8rot7O4QhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantics\n",
        "\n",
        "Word ka matlab samajhna ‚Äî context ke basis pe.\n",
        "\n",
        "üß† Example:\n",
        "\"Bank\" = financial vs river bank ‚Üí GPT or BERT handle this"
      ],
      "metadata": {
        "id": "91Pp56j-4WIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pragmatics\n",
        "\n",
        "User ki niyat samajhna ‚Äî not literal meaning\n",
        "\n",
        "üß† ‚ÄúCan you pass the salt?‚Äù = request, not a question\n",
        "‚Üí Hard to code, used in LLMs and dialog agents"
      ],
      "metadata": {
        "id": "K-sP78Gr4bFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discourse\n",
        "\n",
        "Link between sentences.\n",
        "\n",
        "üß† Example:\n",
        "\n",
        "\"I'm cold.\"\n",
        "\"I'll close the window.\"\n",
        "\n",
        "‚Üí Second sentence is a reply to the first."
      ],
      "metadata": {
        "id": "EjggJIVS4hof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag of Words\n",
        "\n",
        "Text ‚Üí word frequency dict\n",
        "Grammar & order nahi chahiye.\n",
        "\n"
      ],
      "metadata": {
        "id": "sj-3fWP34l_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\"I love NLP\", \"NLP loves me\"]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())\n"
      ],
      "metadata": {
        "id": "PSPw6zuH4qiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# n-grams\n",
        "\n",
        "Group of n words ‚Äî for phrase detection."
      ],
      "metadata": {
        "id": "H4Hsxk_E4soU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text = [\"I love NLP\"]\n",
        "vectorizer = CountVectorizer(ngram_range=(2, 2))  # bigrams\n",
        "X = vectorizer.fit_transform(text)\n",
        "print(vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "id": "1T1uxsA-4yws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition (NER)\n",
        "\n",
        "Detect names, places, organizations from text."
      ],
      "metadata": {
        "id": "E7ShTgaP41Ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"Barack Obama was born in Hawaii.\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, \"‚Üí\", ent.label_)\n"
      ],
      "metadata": {
        "id": "dCSGwbyD46WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis\n",
        "\n",
        "Text ka tone ‚Äî positive, negative, neutral?"
      ],
      "metadata": {
        "id": "wuMY1GcM5CAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text = \"I absolutely love this movie!\"\n",
        "blob = TextBlob(text)\n",
        "print(blob.sentiment)\n"
      ],
      "metadata": {
        "id": "nUIwiEtp5HP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keyword Extraction\n",
        "\n",
        "Most important words from a passage."
      ],
      "metadata": {
        "id": "9EOQG9r_5KpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "docs = [\"battery life is great\", \"screen quality is amazing\"]\n",
        "tfidf = TfidfVectorizer()\n",
        "X = tfidf.fit_transform(docs)\n",
        "print(tfidf.get_feature_names_out())\n",
        "print(X.toarray())\n"
      ],
      "metadata": {
        "id": "MOmHcU5M5Pia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistical Language Modeling\n",
        "\n",
        "Probability of next word.\n",
        "‚ÄúToday is a sunny‚Ä¶‚Äù ‚Üí likely next = ‚Äúday‚Äù\n",
        "\n",
        "üß† Used in GPT/BERT\n",
        "‚ö° Needs big corpus + LSTM/Transformer models (advanced)"
      ],
      "metadata": {
        "id": "xYbmumj15RvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speech Recognition\n",
        "\n",
        "Speech ‚Üí Text"
      ],
      "metadata": {
        "id": "O1P3SzGY5W4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "r = sr.Recognizer()\n",
        "with sr.Microphone() as source:\n",
        "    print(\"Speak:\")\n",
        "    audio = r.listen(source)\n",
        "    print(\"You said:\", r.recognize_google(audio))\n"
      ],
      "metadata": {
        "id": "P9V2J5695dRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Generation (NLG)\n",
        "\n",
        "AI writes text (like ChatGPT does)\n",
        "\n",
        "Use:\n",
        "\n",
        "1. GPT-2\n",
        "\n",
        "2. T5\n",
        "\n",
        "3. OpenAI APIs"
      ],
      "metadata": {
        "id": "0lLvXKge5hOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Sense Disambiguation\n",
        "\n",
        "Same word, different meanings?\n",
        "‚ÄúBat‚Äù ü¶á vs. üèè\n",
        "\n",
        "üß† Use: Contextual models like BERT or WordNet similarity"
      ],
      "metadata": {
        "id": "E-U9tTY75x4X"
      }
    }
  ]
}